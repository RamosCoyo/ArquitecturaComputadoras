<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Unidad 1</title>
  <link rel="stylesheet" href="/css/style.css">
  <link rel="icon" type="image/ico" href="/images.ico">
</head>
<body>
  <!-- Barra de navegación -->
<div class="navbar">
  <a href="https://saltillo.tecnm.mx">Institucion</a>
  <a href="/paginas/Contacto.html">Contacto</a>
  <a href="https://ramoscoyo.github.io/ArquitecturaComputadoras/index.html">Inicio</a>
</div>
<br>
<br>
<!-- Contenido de la página -->
<div style="padding:20px">
  <h2>Arquitectura de Computadoras</h2>
</div>
<!-- Línea separadora -->
<hr class="linea-separadora">
<h2>Unidad 1</h2>

</div>
<!-- Línea separadora -->
<hr class="linea-separadora2">
<br><br>

<div class="contenedor-rectangulo">
    <h2>1.1 Modelos de arquitectura de computo.</h2>
    <p style="font-size: 20px;">En el mundo de la informática, la arquitectura de computadoras se refiere a la organización estructural y funcional de los componentes básicos que conforman un sistema computacional. <br>Esencialmente, define cómo se interconectan y trabajan en conjunto las distintas partes de una computadora para lograr el procesamiento de datos y la ejecución de programas.
        En este contexto, los modelos de arquitectura de computadoras se clasifican en diferentes tipos, cada uno con sus propias características y enfoques para la organización de los componentes..
      <img src="ModelosArqui.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;">
    </p>

    </br>

        <h1>1.1.1 Clasicas.</h1>
        <p style="font-size: 20px;">
<br>
            Propuesta por John von Neumann en 1945, la arquitectura Von Neumann es considerada el modelo fundamental de las computadoras modernas.
<br>
Se caracteriza por las siguientes propiedades:

            Estructura basada en una memoria principal única: Esta memoria almacena tanto las instrucciones del programa como los datos necesarios para su ejecución.
<br>
Unidad central de procesamiento (CPU): La CPU es el "cerebro" del sistema, encargada de ejecutar las instrucciones del programa.
<br>
Bus de datos: Un canal de comunicación que permite la transferencia de datos entre la CPU, la memoria y los dispositivos de entrada/salida (E/S).
<br>
Control centralizado: La CPU controla el flujo de datos y la ejecución de instrucciones mediante una unidad de control.
<br>
Ventajas:        
<br>
°Simplicidad de diseño y programación
<br>
°Facilidad de implementación
<br>
Desventajas:
            
<br>
°Cuello de botella en el bus de datos, lo que puede limitar el rendimiento
<br>
°Menor flexibilidad en el diseño <br>
<img src="/img/Von.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;">
        </p>
        
        
    <p style="font-size: 20px;">
        Modelo Harvard<br>
        Esta arquitectura utiliza los Micro controladores, tiene la unidad central de proceso (CPU) conectada a dos memorias (una con las instrucciones y otra con los datos) por medio de dos buses diferentes.
        Una de las memorias contiene solamente las instrucciones del programa (Memoria de Programa), y la otra sólo almacena datos (Memoria de Datos).
        Ambos buses son totalmente independientes lo que permite que la CPU pueda acceder de forma independiente y simultánea a la memoria de datos y a la de instrucciones.
        El tamaño de las instrucciones no está relacionado con el de los datos, y por lo tanto puede ser optimizado para que cualquier instrucción ocupe una sola posición de memoria de programa, logrando así mayor velocidad y menor longitud de programa.
        La principal desventaja de esta arquitectura; el bus de datos y direcciones único se convierte en un cuello de botella por el cual debe pasar toda la información que se lee de o se escribe a la memoria, obligando a que todos los accesos a esta sean secuenciales.
        Limita el grado de paralelismo (acciones que se pueden realizar al mismo tiempo) y por lo tanto, el desempeño de la computadora.
    </p>
    <img src="/img/Harvard.png" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

<h1>1.1.2 Segmentadas.</h1>
<p style="font-size: 20px;">
    Es una de las tecnologías utilizadas para realizar la segmentación o paralelismo. Divide el procesador, en etapas, procesa una instrucción diferente en cada una y trabaja con varias a la vez.
    Pueden trabajar de forma paralela, en diferentes instrucciones, utilizando una cola de instrucciones para su comunicación, denominado entubamiento.
    La técnica de implementación clave utilizada para hacer CPU.
    La dependencia de datos y de control, que tiene como efecto la disminución del rendimiento del pipelining.
    La segmentación de cauce (pipelining) es una forma efectiva de organizar el hardware del CPU para realizar más de una operación al mismo tiempo.
    Consiste en descomponer el proceso de ejecución de las instrucciones en fases o etapas que permitan una ejecución simultánea.
    Las etapas están conectadas, cada una a la siguiente, para formar una especie de cauce las instrucciones se entran por un extremo, son procesadas a través de las etapas y salen por el otro. La productividad de la segmentación está determinada por la frecuencia con que una instrucción salga del cauce.
</p>
<img src="/img/Seg.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

<h1>1.1.3 Multiprocesamiento</h1>
<p style="font-size: 20px;">
    Un modelo de multiprocesamiento (MP) es una arquitectura de computadora que utiliza dos o más procesadores (CPUs) para ejecutar programas y procesar datos simultáneamente. Esto permite mejorar el rendimiento general del sistema al distribuir la carga de trabajo entre múltiples CPUs.
<br>
    Existen dos tipos principales de modelos de multiprocesamiento:
    <br>
    <br>1. Multiprocesamiento simétrico (SMP):
    <br>
    En un sistema SMP, todos los procesadores comparten la misma memoria principal y el espacio de direcciones. Esto significa que cualquier procesador puede acceder a cualquier dato o instrucción almacenada en la memoria. Los sistemas SMP son comunes en computadoras personales de escritorio y servidores de gama baja.
    <br>
    Ventajas de SMP:
    <br>
    Simplicidad: La arquitectura SMP es relativamente simple de diseñar y programar.
    Escalabilidad: Es posible agregar más procesadores a un sistema SMP para mejorar el rendimiento.
    Costo: Los sistemas SMP suelen ser más económicos que otros modelos de multiprocesamiento.
    Desventajas de SMP:
    <br>
    Contención de bus: El bus de memoria puede convertirse en un cuello de botella si varios procesadores intentan acceder a la memoria simultáneamente.
    Escalabilidad limitada: La escalabilidad de los sistemas SMP está limitada por el número de procesadores que se pueden conectar a un solo bus de memoria.
    <br>2. Multiprocesamiento no simétrico (NUMA):
    <br>
    En un sistema NUMA, cada procesador tiene su propia memoria local y un espacio de direcciones privado. Los procesadores también pueden acceder a la memoria global, pero el acceso a la memoria local es más rápido. Los sistemas NUMA son comunes en servidores de gama alta y supercomputadoras.
    <br>
    Ventajas de NUMA:
    <br>
    Rendimiento: Los sistemas NUMA pueden ofrecer un mayor rendimiento que los sistemas SMP, especialmente para aplicaciones que realizan muchos accesos a la memoria.
    Escalabilidad: Los sistemas NUMA son más escalables que los sistemas SMP, ya que se pueden agregar más procesadores y memoria sin crear cuellos de botella en el bus.
    Desventajas de NUMA:
    <br>
    Complejidad: La arquitectura NUMA es más compleja de diseñar y programar que la SMP.
    Costo: Los sistemas NUMA suelen ser más costosos que los sistemas SMP.
    <br>3. Otros modelos de multiprocesamiento:
    <br>
    Además de SMP y NUMA, existen otros modelos de multiprocesamiento menos comunes, como:
    <br>
    Multiprocesamiento con memoria distribuida (DMP): En un sistema DMP, la memoria se distribuye entre varios nodos, cada uno con su propio procesador.
    Multiprocesamiento jerárquico: En un sistema de multiprocesamiento jerárquico, los procesadores se organizan en una jerarquía, con algunos procesadores controlando a otros.
    Elección del modelo de multiprocesamiento:
    <br>
    El modelo de multiprocesamiento más adecuado para una aplicación específica depende de varios factores, como el tipo de aplicación, el rendimiento requerido, la escalabilidad deseada y el presupuesto.
</p>
<img src="/img/Multi.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >
</div>
<br>
<div class="contenedor-rectangulo">
    <h2>1.2 Analisis de los componentes.</h2>
    <p style="font-size: 20px;">Una computadora se compone de dos partes fundamentales: hardware y software. El hardware es la parte física de la computadora, mientras que el software es la parte intangible que le da vida a la máquina.</p>
    <img src="/img/Analis.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.1 Arquitectura</h1>
    <p style = "font-size: 20px;">
        Arquitecturas Cisc
        En la arquitectura computacional, CISC es un modelo de arquitectura, en donde los microprocesadores tienen un conjunto instrucciones que caracterizan por ser muy amplio y permitir operaciones complejas entre operandos, situados en la memoria o en los registros internos.
        Este tipo de arquitectura dificulta el paralelismo entre instrucciones, por lo que, en la actualidad, la mayoría de los sistemas CISC de alto rendimiento implementan un sistema que convierte dichas instrucciones complejas en varias instrucciones simples del tipo RISC, llamadas generalmente microinstrucciones.
        Dato importante: Los CISC pertenecen a la primera corriente de construcción de procesadores, antes del desarrollo de los RISC.
        Ademas Para realizar una sola instrucción un chip CISC requiere de cuatro a diez ciclos de reloj.
        Entre las ventajas de CISC destacan las siguientes:
        Reduce la dificultad de crear compiladores.
        Permite reducir el costo total del sistema.
        Reduce los costos de creación de software.
        Mejora la compactación de código.
        Facilita la depuración de errores.
        Arquitecturas Cisc
        Arquitectura computacional, RISC (Reduced Instruction Set Computer) es un tipo de microprocesador con las siguientes características fundamentales:
        Instrucciones de tamaño fijo y presentado en un reducido número de formatos.
        Sólo las instrucciones de carga y almacenamiento acceden a la memoria de datos.
        El objetivo de diseñar máquinas con esta arquitectura es posibilitar la segmentación y el paralelismo en la ejecución
        de instrucciones y reducir los accesos a memoria.
        Las máquinas RISC protagonizan la tendencia actual de construcción de microprocesadores.
    </p>
    <img src="/img/CISC.png" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.1.1 Unidad Central de Procesamiento</h1>
    <p style="font-size: 20px;">
        Se la suele llamar coloquialmente como microprocesador o simplemente procesador, y puedes considerarla como el cerebro de cualquier dispositivo.
        Se encarga de procesar todas las instrucciones del dispositivo, leyendo las órdenes y requisitos del sistema operativo, así como las instrucciones de cada uno de los componentes y las aplicaciones.
        CPU es la que se encarga de que todo funcione correctamente, y de interpretar todo lo que quiere hacer el sistema operativo o los componentes, estableciendo las conexiones y realizando todos los cálculos precisos para que funcione.
        Cuanto más potente sea el procesador, más rápido podrá hacer las operaciones y más rápido funcionará tu dispositivo en general.
        Los CPUs modernos se pueden clasificar por sus características como:
        Tamaño de la Unidad Aritmética Lógica (ALU).
        Bus de conexión al exterior (8, 16, 32, 64 bits).
        Si su arquitectura tiene cauce (pipeline).
        Si son de arquitectura CISC o RISC.
        Si son Von Newmann o Harvard.
        Si manejan instrucciones enteras o implementan también instrucciones de punto flotante.
        No hace mucho tiempo, el procesador era algo totalmente desconocido por los usuarios de PCs.
        Esto fue cambiando con el tiempo y en la actualidad cualquier persona al comprar un equipo se pregunta acerca de los atributos elementales de este dispositivo.
        Es que el procesador es una parte esencial de la computadora, por eso generalmente se la conoce como su “cerebro”.
        
    </p>
    <img src="/img/portada.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.1.2 Unidad Aritmética Logica</h1>
    <p style="font-size: 20px;">
        La Unidad Aritmético Lógica (ALU), también conocida por sus siglas en inglés Arithmetic Logic Unit, es un circuito digital fundamental en la arquitectura de una computadora. Se encarga de realizar operaciones aritméticas (suma, resta, multiplicación, división) y operaciones lógicas (AND, OR, NOT, XOR) sobre datos binarios.
<br>
        Función principal:
        <br>
        La ALU es el corazón del procesador, donde se llevan a cabo los cálculos y las comparaciones que permiten ejecutar las instrucciones de los programas. Es el componente que manipula los datos de acuerdo con las instrucciones recibidas de la Unidad de Control (CU).
        <br>
        Estructura:
        <br>
        En general, una ALU se compone de los siguientes elementos:
        <br>
        <br>        Registros de entrada: Almacenan los datos binarios que se van a procesar.
        <br>   Circuito operacional: Realiza las operaciones aritméticas y lógicas sobre los datos.
        <br>  Registro acumulador: Almacena el resultado de las operaciones.
        <br>   Unidades de control: Controlan el flujo de datos y las operaciones a realizar.
        Tipos de operaciones:
        <br>
        Las operaciones que puede realizar una ALU se clasifican en dos grupos:
        <br>
        Operaciones aritméticas:
        <br>
        <br>    Suma
        <br>    Resta
        <br>   Multiplicación
        <br>   División
        <br>  Cambio de signo
        <br>   Comparaciones (mayor que, menor que, igual que)
        <br>   Operaciones lógicas:
        <br>  
        <br>  AND (y binario)
        <br>  OR (o binario)
        <br> NOT (negación)
        <br> XOR (o exclusivo)
        <br>  Importancia:
        <br> 
        La ALU es un componente esencial en el funcionamiento de una computadora, ya que es la responsable de realizar los cálculos y las comparaciones que permiten ejecutar las instrucciones de los programas. Sin la ALU, las computadoras no podrían funcionar.
    </p>
    <img src="/img/ALU.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.1.3 Registros</h1>
    <p style="font-size: 20px;">
        Los registros que encuentran dentro de cada procesador su función principales almacenar los valores de cada uno de los datos,comandos,instrucciones o estados binarios que son los que ordenan qué dato debe procesarse, así como la forma en la que se debe realizar.
        Un registro no deja de ser una memoria de velocidad alta y con poca capacidad.
        Cada registro puede contener una instrucción, una dirección de almacenamiento o cualquier tipo de dato.
        Cada procesador tiene varias asignaciones o tareas que debe de realizar para el manejo de la información.
        La información es recibida generalmente en código binario, procedente de las aplicaciones para, después, procesarlos de una forma determinada.
        Tipos de registros
        Los registros del procesador se dividen o clasifican atendiendo al propósito que sirven o a las instrucciones que les ordenan.
        Registros de datos: Guardan valores de datos numéricos, como son los caracteres o pequeñas órdenes.
        Los procesadores antiguos tenían un registro especial de datos: el acumulador, el cual era usado para operaciones determinadas.
        Registros de datos de memoria (MDR): Es un registro que se encuentra en el procesador y que está conectado al bus de datos.
        Tiene poca capacidad y una velocidad alta por la que escribe o lee los datos del bus que van dirigidos a la memoria o al puerto E/S, es decir, un periférico.
        Registros de direcciones: Guardan direcciones que son usadas para acceder a la memoria principal o primaria, que solemos conocer como ROM o RAM.
        En este sentido, podemos ver procesadores con registros que se usan solo para guardar direcciones o valores numéricos.
        Registros de propósito general (GPRs): Son registros que sirven para almacenar direcciones o datos generales.
        Se trata de una especie de registros mixtos que, como su propio indica, no tienen una función específica.
        Registros de propósito específico (SPRs): En esta ocasión, estamos ante registros que guardan datos del estado del sistema, como puede ser el registro de estado o el instruction pointer.
        Registros de estado: Sirven para guardar valores reales cuya función es determinar cuándo una instrucción debe ejecutarse o no.
        Registros constantes: Su cometido es guardar valores de sólo lectura como son el 0, 1 ó π.
    </p>
    <img src="/img/Registros.png" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.1.4 Buses</h1>
    <p style="font-size: 20px;">
        Un bus se puede definir como una línea de interconexión portadora de información, constituida por varios hilos conductores (en sentido físico) o varios canales (en sentido de la lógica), por cada una de las cuales se transporta un bit de información.
        Existen dos tipos primordiales de buses (conexiones) para el envío de la información: bus paralelo o serial:
        Bus paralelo: Es un bus en el cual los datos son enviados por bytes al mismo tiempo, con la ayuda de varias líneas que tienen funciones fijas.
        La cantidad de datos enviada es bastante grande con una frecuencia moderada y es igual al ancho de los datos por la frecuencia de funcionamiento.
        En los computadores ha sido usado de manera intensiva, desde el bus del procesador, los buses de discos duros, tarjetas de expansión y de vídeo hasta las impresoras.
        Bus serie: En este los datos son enviados, bit a bit y se reconstruyen por medio de registros o rutinas de software. Está formado por pocos conductores y su ancho de banda depende de la frecuencia. Es usado desde hace menos de 10 años en buses para discos duros, tarjetas de expansión y para el bus del procesador.
        Buses del procesador:
        Bus de direcciones: Es unidireccional debido a que la información fluye es una solo sentido, del CPU a la memoria ó a los elementos de entrada y salida.
        El CPU puede colocar niveles lógicos en las n líneas de dirección, con la cual se genera 2n posibles direcciones diferentes.
        Cada una de estas direcciones corresponde a una localidad de la memoria ó dispositivo de E/S.
        El procesador envía un código de dirección a la memoria o a otro dispositivo externo.
        El tamaño o anchura del bus de direcciones está especificado por el número de hilos conductores o pines.
        Bus de datos: Es bidireccional, pues los datos pueden fluir hacia ó desde el CPU.Las terminales pueden ser entradas ó salidas, según la operación que se este realizando (lectura ó escritura).
        En todos los casos, las palabras de datos transmitidas tiene m bits de longitud debido a que el CPU maneja palabras de datos de m bits; del número de bits del bus de datos, depende la clasificación del procesador.
        En algunos procesadores, el bus de datos se usa para transmitir otra información además de los datos.Es compartido en el tiempo ó multiplexado. Transfieren datos o códigos de instrucción hacia el procesador o se envían hacia el exterior los resultados de las operaciones o cálculos.
        Bus de control: Este conjunto de señales se usa para sincronizar las actividades y transacciones con los periféricos del sistema.
        Algunas de estas señales, como Lectura o Escritura R / W , son señales que el CPU envía para indicar que tipo de operación se espera en ese momento.
        
    </p>
    <img src="/img/Bus.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.2 Memoria </h1>
    <p style="font-size: 20px;">
        Es un dispositivo que puede mantenerse en por lo menos dos estados estables por un cierto periodo de tiempo.
        Cada uno de estos estados estables puede utilizarse para representar un bit.
        A un dispositivo con la capacidad de almacenar por lo menos un bit se le conoce como celda básica de memoria.
        Un dispositivo de memoria completo se forma con varias celdas básicas y los circuitos asociados para poder leer y escribir dichas celdas básicas, agrupadas como localidades de memoria que permitan almacenar un grupo de N bits.
    </p> 
    <img src="/img/Memoria.png" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.2.1 Conceptos Basicos del Manejo de la Memoria </h1>
    <p style="font-size: 20px;">
        La gestión de memoria o administración de memoria es el acto de gestionar la memoria de un dispositivo informático.
        El proceso de asignación de memoria a los programas que la solicitan.
        La gestión de la memoria principal de una computadora es una tarea de suma importancia para el funcionamiento de la misma.
        Los sistemas de memoria virtual separan las direcciones de memoria utilizadas por un proceso de las direcciones físicas reales, permitiendo la separación de procesos e incrementando la cantidad efectiva de memoria de acceso aleatorio utilizando la paginación. La calidad de la gestión de la memoria es crucial para las prestaciones del sistema.
        La administración de memoria se refiere a los distintos métodos y operaciones que se encargan de obtener la máxima utilidad de la memoria, organizando los procesos y programas que se ejecutan de manera tal que se aproveche de la mejor manera posible el espacio disponible.
        Las técnicas que existen para la carga de programas en la memoria son: partición fija, que es la división de la memoria libre en varias partes (de igual o distinto tamaño) y la partición dinámica, que son las particiones de la memoria en tamaños que pueden ser variables, según la cantidad de memoria que necesita cada proceso.
    </p> 
    <img src="/img/memopri.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.2.2 Memoria Principal </h1>
    <p style="font-size: 20px;">
        La memoria del semiconductor utiliza en su arquitectura circuitos integrados basados en semiconductores para almacenar información.
        Un chip de memoria de semiconductor puede contener millones de minúsculos transistores o condensadores.
        Existen memorias de semiconductor de ambos tipos: volátiles y no volátiles.
        En las computadoras modernas, la memoria principal consiste casi exclusivamente en memoria de semiconductor volátil y dinámica, también conocida como memoria dinámica de acceso aleatorio o más comúnmente RAM (Random Access Memory).
        
    </p> 
    <img src="/img/mempri.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.2.2 Memoria Cache </h1>
    <p style="font-size: 20px;">
        Es la memoria de acceso rápido de una computadora, que guarda temporalmente las últimas informaciones procesadas.
        La memoria caché es un búfer especial de memoria que poseen las computadoras, que funciona de manera similar a la memoria principal, pero es de menor tamaño y de acceso más rápido. Es usada por el procesador para reducir el tiempo de acceso a datos ubicados en la memoria principal que se utilizan con más frecuencia.
        La caché es una memoria que se sitúa entre la unidad central de procesamiento (CPU) y la memoria de acceso aleatorio (RAM) para acelerar el intercambio de datos.
        Cuando se accede por primera vez a un dato, se hace una copia en la caché; los accesos siguientes se realizan a dicha copia, haciendo que sea menor el tiempo de acceso medio al dato.
        Cuando el procesador necesita leer o escribir en una ubicación en memoria principal, primero verifica si una copia de los datos está en la memoria caché; si es así, el procesador de inmediato lee o escribe en la memoria caché, que es mucho más rápido que de la lectura o la escritura a la memoria principal.
        La memoria caché cuenta con 3 niveles, cada uno teniendo más caché pero siendo mas lenta, siendo la de nivel 3 la más lenta.
        
    </p> 
    <img src="/img/cache.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.3 Manejo de la Entrada/Salida </h1>
    <p style="font-size: 20px;">
        El manejo de E/S es un proceso fundamental en la informática que permite a un sistema operativo interactuar con dispositivos periféricos, como teclados, monitores, impresoras, unidades de disco duro, etc.
    </p> 
    <img src="/img/e-s.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.3.1 Modulos de Entrada/Salida </h1>
    <p style="font-size: 20px;">
        Para poder hacer una operación entre el procesador y un periférico, se necesita conectar estos dispositivos a la computadora y gestionar de manera correcta la transferencia de datos. Esto, se puede realizar mediante los sistemas de módulos de Entrada/Salida. Estos módulos están conectados con el procesador y la memoria principal, cada uno controla uno o más dispositivos externos.

    </p> 
    <img src="/img/bloqes.jpg" alt="Texto alternativo de la imagen"  style="display: block; margin: 0 auto;" >

    <h1>1.2.3.2 Entrada/Salida Programada </h1>
    <p style="font-size: 20px;">
        La entrada-salida programada (también entrada / salida programada , E / S programada , PIO ) es un método de transmisión de datos , a través de entrada / salida (E / S), entre una unidad central de procesamiento (CPU) y un dispositivo periférico , como un adaptador de red o un dispositivo de almacenamiento Parallel ATA (PATA, anteriormente AT Attachment (ATA)). Cada transferencia de elementos de datos se inicia mediante una instrucción en el programa, que involucra a la CPU para cada transacción.
        Por el contrario, en las operaciones de acceso directo a memoria (DMA), la CPU no participa en la transferencia de datos.
        El término puede referirse a E / S mapeadas en memoria (MMIO) o E / S mapeadas en puertos (PMIO).
        PMIO se refiere a transferencias que utilizan un espacio de direcciones especial fuera de la memoria normal, al que generalmente se accede con instrucciones dedicadas, comoEN y FUERAen arquitecturas x86.
        MMIO [1] se refiere a transferencias a dispositivos de E / S que están mapeados en el espacio de direcciones normal disponible para el programa.
        PMIO fue muy útil para los primeros microprocesadores con espacios de direcciones pequeños, ya que los dispositivos de E / S no consumían el valioso recurso.
    </p> 
    
    <h1>1.2.3.3 Entrada/Salida Mediante Interrupciones </h1>
    <p style="font-size: 20px;">
        Esta técnica pretende evitar que el procesador pare o haga trabajo improductivo, mientras que espera a que el periférico esté preparado para hacer una nueva operación.
        El hardware de la computadora, necesita tener un conjunto de líneas de control del bus del sistema y de petición de interrupción.
        Funcionamiento:
        El procesador ejecuta instrucciones de un programa. Al finalizar cada instrucción comprueba si se ha producido una interrupción.
        En caso afirmativo se salva el estado actual del programa (contador del programa y registros) y se salta a ejecutar la rutina de servicio correspondiente.
        La rutina de servicio efectúa las operaciones apropiadas en la E/S para realizar la transferencia de datos solicitada.
        Al finalizar la rutina de servicio se recupera el estado de la CPU y se continúa ejecutando el programa que se estaba ejecutando antes de la interrupción.
        Las interrupciones pueden ser:
        ENMASCARABLES (se pueden dejar de atender por software)
        NO ENMASCARABLES (siempre atendidas)
        Dos formas de conocer la dirección/posición (vector) donde se encuentra la rutina de servicio de la interrupción
        Vector de interrupciones siempre FIJO ó el periférico suministra el vector de interrupción
        
    </p> 
    
    <h1>1.2.3.4 Acceso Directo a Memoria </h1>
    <p style="font-size: 20px;">
        El DMA (acceso directo a la memoria) permite que el dispositivo de red mueva los datos del paquete directamente a la memoria del sistema, reduciendo la utilización de la CPU. Sin embargo, la frecuencia y los intervalos aleatorios en los cuales los paquetes llegan no permiten que el sistema ingrese un estado de energía más bajo.
        El coalescentes DMA permite que el NIC recoja los paquetes antes de que inicie un evento DMA. Esto puede aumentar la latencia de la red, pero también aumenta las probabilidades de que el sistema consuma menos energía.
        Los adaptadores y dispositivos de red basados en el controlador Ethernet Intel® I350 (y controladores posteriores) Asistencia la fusión de DMA.
        Los valores coalescentes más altos de DMA resultan en más energía guardada, pero pueden aumentar la latencia de red de su sistema.
        Si habilita la coalescación de DMA, también debe establecer la tasa de moderación de interrupciones en "mínimo".
        Esto minimiza el impacto de latencia impuesto por la coalescencia de DMA y da como resultado un mejor rendimiento de rendimiento de red máximo.
        Debe habilitar la coalescencia de DMA en todos los puertos activos del sistema. Usted no puede ganar ningún ahorro de energía si se habilita sólo en algunos de los puertos en su sistema. También hay varias configuraciones de BIOS, plataformas y aplicaciones que afectarán a su potencial ahorro energético.
        
    </p> 
   
    <h1>1.2.3.5 Canales y Procesadores de Entrada/Salida </h1>
    <p style="font-size: 20px;">
        EL canal de E/S es una extensión del bus del 8088. Este canal contiene un bus de datos bidireccinal de 8 bits, 20 líneas de dirección, 6 niveles de interrupción, líneas de control para las operaciones de lectura y escritura para la memoria y la E/S, líneas de control de 3 canales de DMA, y líneas de control para el tiempo de refresco de memoria.
        Los canales de E/S proporcionan una línea Ready para permitir operaciones con dispositivos de memoria o de E/S lentos.
        Cuando la línea no está activada por un dispositivo, el procesador genera ciclos de lectura y esritura a memoria que toman cuatro ciclos de 210 ns (esto es, 840 ns) por byte.
        Todos los ciclos de lectura y escritura a E/S generados por el procesador requieren de cinco ciclos de 210 ns de reloj (1.05 ms) por byte.
        Todas las transferencias DMA requieren de cinco ciclos de reloj para un ciclo de tiempo de 1.05 ms por byte.
        Los ciclos de reloj se presentan aproximadamente cada 15 m sec y requieren de cinco ciclos de reloj.
        Los dispositivos de E/S están direccionados utilizando un mapeo de E/S con el espacio de direccionamiento. El canal proporciona a las tarjetas de E/S 512 direcciones de dispositivos.
        
    </p> 
    
    <h1>1.2.4 Buses </h1>
    <p style="font-size: 20px;">
        En arquitectura de computadores, el bus es un sistema digital que transfiere datos entre los componentes de una computadora. Está formado por cables o pistas en un circuito impreso, dispositivos como resistores y condensadores, además de circuitos integrados.
        Un bus es una trayectoria por la cual viajan los datos en una computadora para comunicar los distintos dispositivos entre sí.
        Los principales buses que se encuentran dentro de una PC son: los Buses del micro-procesador, los Buses de memoria y los Buses del sistema.
        
    </p> 
    
    <h1>1.2.4.1 Tipos de Buses </h1>
    <p style="font-size: 20px;">
        Existen dos tipos de transferencia en los buses:
        Serie: El bus solamente es capaz de transferir los datos bit a bit. El bus tiene un único cable que transmite la información.
        Paralelo: El bus permite transferir varios bits simultáneamente, por ejemplo 8 bits.
        Aunque en primera instancia parece mucho más eficiente la transferencia en paralelo, esta presenta inconvenientes:
        La frecuencia de reloj en el bus paralelo tiene que ser más reducida.
        La longitud de los cables que forman el bus está limitada por las posibles interferencias, el ruido y los retardos en la señal.
        Además, los modernos buses serie están formados por varios canales: En este caso se transmite por varios buses serie simultáneamente.
        En los primeros computadores electrónicos, era muy habitual encontrar buses paralelos, quedando los buses serie dedicados para funciones de menor entidad y dispositivos lentos, como el teclado. La tendencia en los últimos años es reemplazar los buses paralelos por buses serie (que suelen ser multicanal). Estos son más difíciles de implementar, pero están dejando velocidades de transferencia más elevadas, además de permitir longitudes de cable mayores.
    </p> 
    
    <h1>1.2.4.2 Estructura de los buces </h1>
    <p style="font-size: 20px;">
        Un bus es un medio compartido de comunicación constituido por un conjunto de líneas (conductores) que conecta las diferentes unidades de un computador. La principal función de
        un bus será, pues, servir de soporte para la realización de transferencias de información entre dichas unidades.
        La unidad que inicia y controla la transferencia se conoce como master del bus para dicha transferencia, y la unidad sobre la que se realiza la transferencia se conoce como slave. Los papeles de master y slave son dinámicos, de manera que una misma unidad puede realizar ambas funciones en transferencias diferentes.
        Por ejemplo, una unidad de DMA hace de slave en la inicialización que realiza el master, la CPU, para una operación de E/S. Sin embargo, cuando comienza la operación, la unidad de DMA juega el papel de master frente a la memoria, que en esta ocasión hace de slave.
        Para garantizar el acceso ordenado al bus, existe un sistema de arbitraje, centralizado o distribuido, que establece las prioridades cuando dos o más unidades pretenden acceder al mismo tiempo al bus, es decir, garantiza que en cada momento sólo exista un master. Para establecer el tiempo de duración de las transferencias y que sea conocido tanto por el master como por el slave, un bus debe disponer de los medios necesarios para la sincronización master-slave.
    </p> 
   
    <h1>1.2.4.3 Jerarquia de Buces </h1>
    <p style="font-size: 20px;">
        Los computadores modernos tienen por lo menos 4 buses diferentes (bus interno, bus del procesador, bus del caché, bus de memoria, bus local de E/S, bus estándar de E/S).
        Se les considera una jerarquía, porque cada bus se conecta al nivel superior a él dentro del computador, integrando así todas las partes del computador.
        Cada uno es generalmente más lento que el que se encuentra sobre él, siendo el bus del procesador el más rápido tratándose de que este es el dispositivo más rápido del computador. Para mejorar el rendimiento del bus, las jerarquías de buses fueron implementadas cada vez más.   
    </p> 
    
    <h1>1.2.5 Interrupciones</h1>
    <p style="font-size: 20px;">
        Una interrupción consiste en un mecanismo que le permite al hardware la invocación de una rutina fuera del control del programa que está siendo ejecutado. Es una señal recibida por el procesador de una computadora, que indica que debe «interrumpir» el curso de ejecución actual y pasar a ejecutar código específico para tratar esta situación.
        Una interrupción es una suspensión temporal de la ejecución de un proceso, para pasar a ejecutar una subrutina de servicio de interrupción, la cual, por lo general, no forma parte del programa, sino que pertenece al sistema operativo o al BIOS. Una vez finalizada dicha subrutina, se reanuda la ejecución del programa.
        Las interrupciones son generadas por los dispositivos periféricos habilitando una señal del CPU (llamada IRQ del inglés "interrupt request") para solicitar atención del mismo.
        Por ejemplo. cuando un disco duro completa una lectura solicita atención al igual que cada vez que se presiona una tecla o se mueve el ratón.
        La primera técnica que se empleó para esto fue el polling, que consistía en que el propio procesador se encargara de sondear los dispositivos periféricos cada cierto tiempo para averiguar si tenía pendiente alguna comunicación para él. Este método presentaba el inconveniente de ser muy ineficiente, ya que el procesador consumía constantemente tiempo y recursos en realizar estas instrucciones de sondeo.
        
    </p> 
    
</div>
<footer>
  <p>&copy; 2024 - Alejandro Ramos Coyotecatl</p>
</footer>
</body>
</html>
